import time
import cv2
import numpy as np
import pyautogui
from typing import Optional, Tuple, List, Dict
import ctypes
from ultralytics import YOLO  # éœ€è¦å®‰è£…ultralyticsåŒ…
import torch
import os


class image:
    ctypes.windll.shcore.SetProcessDpiAwareness(1)  # Windows 8.1+

    """
    åŠŸèƒ½ï¼šæ ¹æ®è¾“å…¥çš„å›¾ç‰‡åç§°ï¼ŒæŸ¥æ‰¾å…¶åœ¨å±å¹•ä¸Šçš„ä½ç½®
    :param template_path: æ¨¡æ¿å›¾ç‰‡è·¯å¾„
    :param threshold: åŒ¹é…é˜ˆå€¼(0-1)
    """

    def __init__(self, template_path: str, threshold: float = 0.8):
        self.template_path = "../images/" + template_path
        self.threshold = threshold
        self.template = self._load_template()

    """
        åŠ è½½æ¨¡æ¿å›¾ç‰‡
    """

    def _load_template(self) -> np.ndarray:
        try:
            template = cv2.imread(self.template_path, cv2.IMREAD_COLOR)
            if template is None:
                raise FileNotFoundError(f"æ¨¡æ¿å›¾ç‰‡æœªæ‰¾åˆ°: {self.template_path}")
            return template
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æ¨¡æ¿å¤±è´¥: {str(e)}")

    """
        æŸ¥æ‰¾å›¾ç‰‡ä½ç½®
        :return: (x,y)å›¾ç‰‡å·¦ä¸Šè§’åæ ‡ï¼ŒNoneè¡¨ç¤ºæœªæ‰¾åˆ°
    """

    def find_image_position(self) -> Optional[Tuple[int, int]]:
        screen = self.capture_screen()
        result = cv2.matchTemplate(screen, self.template, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, max_loc = cv2.minMaxLoc(result)

        return max_loc if max_val >= self.threshold else None

    """
        æˆªå–å±å¹•åŒºåŸŸ
        :param region: (x1, y1, x2, y2)æˆªå›¾åŒºåŸŸï¼ŒNoneè¡¨ç¤ºå…¨å±
        :return: OpenCVå›¾åƒæ ¼å¼(numpyæ•°ç»„)
    """

    def capture_screen(self, region: Optional[Tuple[int, int, int, int]] = None) -> np.ndarray:
        screenshot = pyautogui.screenshot(region=region)
        screen_bgr = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)
        return screen_bgr


class YOLOImageFinder:
    """
    ä½¿ç”¨YOLOv8æ¨¡å‹åœ¨å±å¹•ä¸ŠæŸ¥æ‰¾ç›®æ ‡å¯¹è±¡

    å‚æ•°:
    model_path: YOLOæ¨¡å‹è·¯å¾„ (å¯ä»¥æ˜¯é¢„è®­ç»ƒæ¨¡å‹æˆ–è‡ªå®šä¹‰æ¨¡å‹)
    conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
    device: ä½¿ç”¨çš„è®¾å¤‡ ('cuda' æˆ– 'cpu')
    """

    def __init__(self, model_path: str = "yolov8n.pt",
                 conf_threshold: float = 0.5,
                 device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.conf_threshold = conf_threshold
        self.device = device
        self.model = self._load_model(model_path)
        self.class_names = self.model.names if hasattr(self.model, 'names') else {}

    def _load_model(self, model_path: str) -> YOLO:
        """åŠ è½½YOLOæ¨¡å‹ï¼Œå¦‚æœæœ¬åœ°ä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½"""
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
            try:
                # å°è¯•ä¸‹è½½æ¨¡å‹
                model = YOLO(model_path)
                model.export(format="pt")  # ç¡®ä¿æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°
                return model
            except Exception as e:
                raise RuntimeError(f"æ— æ³•ä¸‹è½½æ¨¡å‹: {str(e)}")
        return YOLO(model_path).to(self.device)

    def capture_screen(self, region: Optional[Tuple[int, int, int, int]] = None) -> np.ndarray:
        """æ•è·å±å¹•åŒºåŸŸ"""
        screenshot = pyautogui.screenshot(region=region)
        return cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)

    def find_targets(self, region: Optional[Tuple[int, int, int, int]] = None) -> List[Dict]:
        """
        åœ¨å±å¹•ä¸ŠæŸ¥æ‰¾ç›®æ ‡å¯¹è±¡

        è¿”å›:
        List of detections, æ¯ä¸ªæ£€æµ‹ç»“æœåŒ…å«:
            'class_name': ç±»åˆ«åç§°
            'confidence': ç½®ä¿¡åº¦
            'position': (x, y, width, height) è¾¹ç•Œæ¡†ä½ç½®
            'center': (cx, cy) è¾¹ç•Œæ¡†ä¸­å¿ƒåæ ‡
        """
        # æ•è·å±å¹•
        screen = self.capture_screen(region)

        # ä½¿ç”¨YOLOè¿›è¡Œæ¨ç†
        results = self.model(screen, conf=self.conf_threshold, verbose=False)

        detections = []
        for result in results:
            # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
            for box in result.boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡ (xyxyæ ¼å¼)
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())

                # è®¡ç®—ä¸­å¿ƒç‚¹
                cx = (x1 + x2) // 2
                cy = (y1 + y2) // 2

                # è·å–ç±»åˆ«IDå’Œåç§°
                cls_id = int(box.cls)
                class_name = self.class_names.get(cls_id, f"class_{cls_id}")

                # è·å–ç½®ä¿¡åº¦
                conf = float(box.conf)

                detections.append({
                    'class_name': class_name,
                    'confidence': conf,
                    'position': (x1, y1, x2 - x1, y2 - y1),  # (x, y, width, height)
                    'center': (cx, cy)
                })

        return detections

    def find_specific_target(self, target_class: str,
                             region: Optional[Tuple[int, int, int, int]] = None) -> Optional[Tuple[int, int]]:
        """
        æŸ¥æ‰¾ç‰¹å®šç±»åˆ«çš„ç›®æ ‡å¹¶è¿”å›ä¸­å¿ƒåæ ‡

        å‚æ•°:
        target_class: è¦æŸ¥æ‰¾çš„ç›®æ ‡ç±»åˆ«åç§°

        è¿”å›:
        ç›®æ ‡ä¸­å¿ƒåæ ‡ (x, y) æˆ– None (å¦‚æœæœªæ‰¾åˆ°)
        """
        detections = self.find_targets(region)

        # æŸ¥æ‰¾æŒ‡å®šç±»åˆ«çš„ç›®æ ‡
        for detection in detections:
            if detection['class_name'] == target_class:
                return detection['center']

        return None


if __name__ == "__main__":
    # ä¿ç•™æ‚¨åŸæœ‰çš„æµ‹è¯•ä»£ç 
    time.sleep(1)

    # # ä½¿ç”¨åŸæœ‰çš„imageç±»
    # print("===== ä½¿ç”¨ä¼ ç»Ÿå›¾åƒåŒ¹é… =====")
    # ImageMatcher = image("taskTracking.png")
    # position = ImageMatcher.find_image_position()  # æŸ¥æ‰¾ä»»åŠ¡æ åæ ‡
    # if position:
    #     x, y = position
    #     region = (max(0, x - 5), max(0, y - 5), 230, 300)
    #     screen = ImageMatcher.capture_screen(region=region)  # è¿”å›ä»»åŠ¡æ æˆªå›¾
    #     print(f"ç›®æ ‡ä½ç½®: {position}, æˆªå›¾åŒºåŸŸ: {region}")
    # else:
    #     print("æœªæ‰¾åˆ°ç›®æ ‡")

    # ä½¿ç”¨YOLOv8è¿›è¡Œç›®æ ‡æ£€æµ‹
    print("\n===== ä½¿ç”¨YOLOv8ç›®æ ‡æ£€æµ‹ =====")

    # åˆå§‹åŒ–YOLOæŸ¥æ‰¾å™¨ - ä½¿ç”¨æ‚¨è®­ç»ƒå¥½çš„æ¨¡å‹
    # æ³¨æ„ï¼šå°†"your_trained_model.pt"æ›¿æ¢ä¸ºæ‚¨å®é™…è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
    yolo_finder = YOLOImageFinder(model_path="your_trained_model.pt", conf_threshold=0.7)

    # æŸ¥æ‰¾ç‰¹å®šç›®æ ‡ (ä¾‹å¦‚ 'taskbar_icon')
    target_position = yolo_finder.find_specific_target("taskbar_icon")

    if target_position:
        x, y = target_position
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡ä½ç½®: ({x}, {y})")

        # å›´ç»•ç›®æ ‡ä½ç½®æˆªå›¾
        region = (max(0, x - 100), max(0, y - 50), 200, 100)
        screen = yolo_finder.capture_screen(region=region)

        # ä¿å­˜æˆªå›¾
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"yolo_target_{timestamp}.png"
        cv2.imwrite(filename, screen)
        print(f"ğŸ’¾ æˆªå›¾å·²ä¿å­˜ä¸º: {filename}")
    else:
        print("âŒ æœªæ‰¾åˆ°ç›®æ ‡")